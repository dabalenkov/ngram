<html>
<head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <title>N-Gram Text-Topic Analysis</title>
</head>
<body>
 <h1>N-Gram Text-Topic Analysis</h1>
 <p>The "N-Gram Text-Topic Analysis" plug-in aims to identify the topic of a given text. As the name of the plug-in indicates, it is based on an n-gram analysis. The n-gram analysis might be explained using the following sentence: “This is a short sentence.” The 2-grams in this sentence would be then “Th”, “hi”, “is” and so on. The 3-grams are “Thi”, “his”, etc. </p>

 <p>It was found out that the best results of identifying a topic are achieved using 2-grams or 3-grams analysis. Since for instance, it would rather not make sense to build a hypothesis based on 8-grams or histograms (1-grams). Here, we used a combination of the 2- and 3-grams distances to build a hypothesis.</p>

 <p>
Right now, the plug-in supports 5 topics:
<ol>
 <li>Football news,</li>
 <li>Political news,</li>
 <li>Literature,</li>
 <li>Law, and</li>
 <li>[Board] Game rules.</li>
</ol>
</p>

 <h4>Plug-in Instructions</h4>

<p>The user can setup the following parameters (see the screenshot below):
<dl>
        <dt><i>Input method:</i></dt>
  <dd>Here one can choose the source of the text to be analyzed. By default this parameter is set to <i>From manual input</i> so that the user can easily copy & paste text. The other option is to load the text <i>From file</i>. Furthermore, the user can choose to load a sample text in English or German for easier testing and understanding of the plug-in.<br /></dd>
  <p></p> <!-- Kommentar: Leerzeile erzwingen -->

        <dt><i>Language:</i></dt>
        <dd>This version of the plug-in supports texts both in <i>English</i> and <i>German</i> languages. More languages are planned to be supported in future versions.</dd>
  <p></p> <!-- Kommentar: Leerzeile erzwingen -->

        <dt><i>Analysis method:</i></dt>
        <dd>To find out what the topic of the given text is the plug-in calculates the distance between the given text and reference texts. The distance can be calculated by using the following methods: <i>Euclidean</i> or <i>Least Squares</i>. These methods are described in detail in "The Algorithm" section below.</dd>
</dl>
</p>

<p align="center">
<img src="tab1.png" width="80%"  alt="The configuration and start tab."></p>

<p>Optionally the user can select one own reference text and see if the topics are identical or not. </p>

<h4>The Algorithm</h4>
<p>
  First, the text is converted to the uppercase, and all the spaces are removed. E.g. from our last example “This is a sentence” becomes “THISISASENTENCE”.<br/><br/>

  Next, the first 50 n-grams (here, as already mentioned before, 2-grams and 3-grams) with the highest frequencies are saved and sorted out in the descending order. Finally, it is compared how different these occurrences are from other references. This is done by using  either the Euclidean or the Least Square distance method: 
  <p></p> <!-- Kommentar: Leerzeile erzwingen -->

  <dt><i>Euclidean:</i></dt>
    <dd>The distance between two grams i and j is defined as |i – j|. E.g. if the sequence “th” in the given text is on the 1st place and in the reference text <i>political news</i> it is on the 4th place, then the distance between them is |1 – 4| = | – 3 | = 3. In a special case, when e.g. in a given text a specific sequence made it to the top 50 most frequent, but in a reference text not, then the distance is defined as 50 – <i>i</i> + 5, where <i>i</i> is the position of the sequence.</dd>
  <p></p> <!-- Kommentar: Leerzeile erzwingen -->

    <dt><i>Least Squares:</i></dt>
    <dd>The main difference to the Euclidean method is that the distances are all squared first and added up. The result is set to the square root of the resulting sum.</dd><br/>
  

  It is worth noting that the longer a given text is, the better results one would achieve. The minimum length of the text is 512 characters.

</p>

<h4>Result field</h4>
<p>The following are two guesses of what the topic of the given text might be as a result of the analysis:<br/><br/>

(★ ★ ★ ★ ☆) 1st guess: This text deals with the topic Literature.<br/>
(★ ★ ☆ ☆ ☆) 2nd guess: This text deals with the topic Football.<br/><br/>

How well the guesses are made is displayed using stars. This is explained below:

<h4>Rating system</h4>
The closer the topic is to one of the reference texts (the smaller distance between the given text and the reference text is), the higher is the rating. In the example above first guess has 4 stars out of 5, whereas the second guess has only 2 stars out of 5. That roughly means that with a very high probability the topic of this text is <i>Literature</i>, and with a lower probability it is <i>Football</i>. <br/><br/>

By testing out about 100 texts of different origin it was found out that the distance to the same topic is usually less than 1050. Whereas the distance to a topic that is completely different the distance is higher than 1350. The exact distances and according ratings can be found in the table below:
<br/><br/>

<table style="width:300px">
<tr>
  <th align="left">Rating</th>
  <th align="left">Distance</th>
</tr>
<tr>
    <td>★ ★ ★ ★ ★</td>
    <td>d < 1050</td>
</tr>  
<tr>
  <td>★ ★ ★ ★ ☆</td> 
  <td> 1050 > d > 1150</td> 
</tr>
<tr>
    <td>★ ★ ★ ☆ ☆</td>
    <td>1150 > d > 1250</td> 
</tr>  
<tr>
    <td>★ ★ ☆ ☆ ☆</td>
    <td>1250 > d > 1350</td>  
</tr>  
<tr>
    <td>★ ☆ ☆ ☆ ☆</td>
  <td>d > 1350</td>     
</tr>  

</table>
<br/>
</p>

</body>
</html>